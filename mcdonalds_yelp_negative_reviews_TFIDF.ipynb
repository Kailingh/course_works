{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-Grams, Regex, and TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are an analyst working at McDonalds' corporate headquarters, and charged with identifying areas for improvement to increase customer service.\n",
    "\n",
    "Using the `mcdonalds-yelp-negative-reviews.csv` dataset, clean and parse the text reviews. \n",
    "\n",
    "Finally, generate a TF-IDF report that **visualizes** for each city what the major source of complaints with the McDonalds franchises are. Offer your analysis and business recommendations on next steps for the global SVP of Operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/kailinghung/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.collocations import BigramCollocationFinder, BigramAssocMeasures\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"mcdonalds-yelp-negative-reviews.csv\", encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1525, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>city</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>679455653</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>I'm not a huge mcds lover, but I've been to be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>679455654</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>Terrible customer service. I came in at 9:30pm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>679455655</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>First they \"lost\" my order, actually they gave...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>679455656</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>I see I'm not the only one giving 1 star. Only...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>679455657</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>Well, it's McDonald's, so you know what the fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    _unit_id     city                                             review\n",
       "0  679455653  Atlanta  I'm not a huge mcds lover, but I've been to be...\n",
       "1  679455654  Atlanta  Terrible customer service. I came in at 9:30pm...\n",
       "2  679455655  Atlanta  First they \"lost\" my order, actually they gave...\n",
       "3  679455656  Atlanta  I see I'm not the only one giving 1 star. Only...\n",
       "4  679455657  Atlanta  Well, it's McDonald's, so you know what the fo..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las Vegas      409\n",
      "Chicago        219\n",
      "Los Angeles    167\n",
      "New York       165\n",
      "Atlanta        130\n",
      "Houston        105\n",
      "Portland        97\n",
      "Dallas          75\n",
      "Cleveland       71\n",
      "Name: city, dtype: int64\n",
      "there are 9 cities\n"
     ]
    }
   ],
   "source": [
    "# city\n",
    "city = data['city'].value_counts()\n",
    "print(city)\n",
    "print(\"there are\",len(data['city'].value_counts()),\"cities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## all reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allreview = list(data[\"review\"].values)\n",
    "type(allreview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word count for all reviews\n",
    "# to find potential customize stop words \n",
    "words = [] \n",
    "word_count = {} \n",
    "\n",
    "for line in allreview: \n",
    "    for word in line.split(\" \"): \n",
    "        words.append(word.lower())\n",
    "        \n",
    "        if word not in word_count.keys(): \n",
    "            word_count[word] = 1\n",
    "        else:\n",
    "            word_count[word] += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "sorted_review = sorted(word_count.items(), key=operator.itemgetter(1),reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First they `` lost '' my order , actually they gave it to someone one else than took 20 minute to figure out why I wa still waiting for my order.They after I wa asked what I needed I replied , `` my order '' .They asked for my ticket and the asst mgr looked at the ticket then incompletely filled it.I had to ask her to check to see if she filled it correctly.She acted a if she could n't be bothered with that so I asked her again.She begrudgingly checked to she did in fact miss something on the ticket.So after 22 minute I finally had my breakfast biscuit platter.As I left an woman approached and identified herself a the manager , she wa dressed a if she had just awoken in an old t-shirt and sweat pants.She said she had heard what happened and said she 'd take care of it.Well why did n't she intervene when she saw I wa growing annoyed with the incompetence ? \n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# lemmatize all review\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemma(lines_review):\n",
    "    sentence1 =[]\n",
    "    for sentence in lines_review:\n",
    "        token_words=word_tokenize(sentence)\n",
    "        token_words\n",
    "        stem_sentence=[]\n",
    "        for word in token_words:\n",
    "            stem_sentence.append(lemmatizer.lemmatize(word))\n",
    "            stem_sentence.append(\" \")\n",
    "        sentence1.append(\"\".join(stem_sentence))\n",
    "    return sentence1\n",
    "\n",
    "allreview = lemma(allreview)\n",
    "\n",
    "print(allreview[2])\n",
    "print(type(allreview))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(2,5),\n",
    "                             token_pattern=r'\\b[a-zA-Z]{3,}\\b',\n",
    "                             max_df=0.5,\n",
    "                             binary = True,\n",
    "                             min_df=2, stop_words=stopwords.words('english')+ ['.', ',',\"'s\", 'wa','', \"n't\",'...',\\\n",
    "                                                                              'mcdonalds','mcdonald','McDonald','McDonalds',\\\n",
    "                                                                              'one','get','would','could','know','even','got',\"fast\",\"food\"]) #customize stops words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(allreview)\n",
    "terms = vectorizer.get_feature_names()\n",
    "tf_idf = pd.DataFrame(X.toarray().transpose(), index=terms)\n",
    "tf_idf = tf_idf.sum(axis=1)\n",
    "score = pd.DataFrame(tf_idf, columns=[\"score\"])\n",
    "score[\"term\"] = terms\n",
    "score.sort_values(by=\"score\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>drive thru</th>\n",
       "      <td>34.117692</td>\n",
       "      <td>drive thru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer service</th>\n",
       "      <td>15.998619</td>\n",
       "      <td>customer service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst ever</th>\n",
       "      <td>11.473978</td>\n",
       "      <td>worst ever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ice cream</th>\n",
       "      <td>10.704884</td>\n",
       "      <td>ice cream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>order wrong</th>\n",
       "      <td>10.451155</td>\n",
       "      <td>order wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>every time</th>\n",
       "      <td>8.786582</td>\n",
       "      <td>every time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>big mac</th>\n",
       "      <td>8.555748</td>\n",
       "      <td>big mac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parking lot</th>\n",
       "      <td>8.139030</td>\n",
       "      <td>parking lot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>order right</th>\n",
       "      <td>8.075159</td>\n",
       "      <td>order right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>late night</th>\n",
       "      <td>7.437414</td>\n",
       "      <td>late night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chicken nugget</th>\n",
       "      <td>6.859327</td>\n",
       "      <td>chicken nugget</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>taking order</th>\n",
       "      <td>6.714832</td>\n",
       "      <td>taking order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>french fry</th>\n",
       "      <td>6.406292</td>\n",
       "      <td>french fry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>place order</th>\n",
       "      <td>6.250073</td>\n",
       "      <td>place order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first time</th>\n",
       "      <td>6.219269</td>\n",
       "      <td>first time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last time</th>\n",
       "      <td>6.109931</td>\n",
       "      <td>last time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iced coffee</th>\n",
       "      <td>6.099065</td>\n",
       "      <td>iced coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>went drive</th>\n",
       "      <td>6.002766</td>\n",
       "      <td>went drive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sweet tea</th>\n",
       "      <td>5.992323</td>\n",
       "      <td>sweet tea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>look like</th>\n",
       "      <td>5.759650</td>\n",
       "      <td>look like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>across street</th>\n",
       "      <td>5.456511</td>\n",
       "      <td>across street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good service</th>\n",
       "      <td>5.395394</td>\n",
       "      <td>good service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>take order</th>\n",
       "      <td>5.385287</td>\n",
       "      <td>take order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dollar menu</th>\n",
       "      <td>5.341013</td>\n",
       "      <td>dollar menu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chicken sandwich</th>\n",
       "      <td>5.219194</td>\n",
       "      <td>chicken sandwich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>service ever</th>\n",
       "      <td>5.157254</td>\n",
       "      <td>service ever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bad service</th>\n",
       "      <td>5.111177</td>\n",
       "      <td>bad service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horrible service</th>\n",
       "      <td>5.035052</td>\n",
       "      <td>horrible service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>happy meal</th>\n",
       "      <td>4.968180</td>\n",
       "      <td>happy meal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hash brown</th>\n",
       "      <td>4.932805</td>\n",
       "      <td>hash brown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      score              term\n",
       "drive thru        34.117692        drive thru\n",
       "customer service  15.998619  customer service\n",
       "worst ever        11.473978        worst ever\n",
       "ice cream         10.704884         ice cream\n",
       "order wrong       10.451155       order wrong\n",
       "every time         8.786582        every time\n",
       "big mac            8.555748           big mac\n",
       "parking lot        8.139030       parking lot\n",
       "order right        8.075159       order right\n",
       "late night         7.437414        late night\n",
       "chicken nugget     6.859327    chicken nugget\n",
       "taking order       6.714832      taking order\n",
       "french fry         6.406292        french fry\n",
       "place order        6.250073       place order\n",
       "first time         6.219269        first time\n",
       "last time          6.109931         last time\n",
       "iced coffee        6.099065       iced coffee\n",
       "went drive         6.002766        went drive\n",
       "sweet tea          5.992323         sweet tea\n",
       "look like          5.759650         look like\n",
       "across street      5.456511     across street\n",
       "good service       5.395394      good service\n",
       "take order         5.385287        take order\n",
       "dollar menu        5.341013       dollar menu\n",
       "chicken sandwich   5.219194  chicken sandwich\n",
       "service ever       5.157254      service ever\n",
       "bad service        5.111177       bad service\n",
       "horrible service   5.035052  horrible service\n",
       "happy meal         4.968180        happy meal\n",
       "hash brown         4.932805        hash brown"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Las Vegas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter only Las Vegas\n",
    "Vegas = data[data.city == 'Las Vegas']\n",
    "r_vegas = list(Vegas['review'].values)\n",
    "\n",
    "# lemmatize all review\n",
    "lemma(r_vegas)\n",
    "\n",
    "# vectorizer1 2-grams\n",
    "vectorizer1 = TfidfVectorizer(ngram_range=(2,5),\n",
    "                             token_pattern=r'\\b[a-zA-Z]{3,}\\b',\n",
    "                             binary = True,\n",
    "                             max_df=0.3,\n",
    "                             min_df=2, stop_words=stopwords.words('english')+ ['.', ',',\"'s\", 'wa','', \"n't\",'...',\\\n",
    "                                                                              'mcdonalds','mcdonald','McDonald','McDonalds',\\\n",
    "                                                                              'one','get','would','could','know','even','got',\"fast\",\"food\"]) #customize stops words\n",
    "\n",
    "# vectorizer2 3-grams\n",
    "vectorizer2 = TfidfVectorizer(ngram_range=(3,3),\n",
    "                             token_pattern=r'\\b[a-zA-Z]{3,}\\b',\n",
    "                             binary = True,\n",
    "                             max_df=0.3,\n",
    "                             min_df=2, stop_words=stopwords.words('english')+ ['.', ',',\"'s\", 'wa','', \"n't\",'...',\\\n",
    "                                                                              'mcdonalds','mcdonald','McDonald','McDonalds',\\\n",
    "                                                                              'one','get','would','could','know','even','got',\"fast\",\"food\"]) #customize stops words\n",
    "\n",
    "# vectorizer3\n",
    "vectorizer3 = TfidfVectorizer(ngram_range=(4,4),\n",
    "                             token_pattern=r'\\b[a-zA-Z]{3,}\\b',\n",
    "                             binary = True,\n",
    "                             max_df=0.3,\n",
    "                             min_df=1, stop_words=stopwords.words('english')+ ['.', ',',\"'s\", 'wa','', \"n't\",'...',\\\n",
    "                                                                              'mcdonalds','mcdonald','McDonald','McDonalds',\\\n",
    "                                                                              'one','get','would','could','know','even','got',\"fast\",\"food\"]) #customize stops words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>drive thru</th>\n",
       "      <td>16.660906</td>\n",
       "      <td>drive thru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer service</th>\n",
       "      <td>6.546794</td>\n",
       "      <td>customer service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>big mac</th>\n",
       "      <td>5.613363</td>\n",
       "      <td>big mac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst ever</th>\n",
       "      <td>4.912069</td>\n",
       "      <td>worst ever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>order right</th>\n",
       "      <td>4.506187</td>\n",
       "      <td>order right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>las vegas</th>\n",
       "      <td>4.467361</td>\n",
       "      <td>las vegas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chicken nuggets</th>\n",
       "      <td>4.337296</td>\n",
       "      <td>chicken nuggets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>order wrong</th>\n",
       "      <td>4.184090</td>\n",
       "      <td>order wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ice cream</th>\n",
       "      <td>4.048424</td>\n",
       "      <td>ice cream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sweet tea</th>\n",
       "      <td>3.812979</td>\n",
       "      <td>sweet tea</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      score              term\n",
       "drive thru        16.660906        drive thru\n",
       "customer service   6.546794  customer service\n",
       "big mac            5.613363           big mac\n",
       "worst ever         4.912069        worst ever\n",
       "order right        4.506187       order right\n",
       "las vegas          4.467361         las vegas\n",
       "chicken nuggets    4.337296   chicken nuggets\n",
       "order wrong        4.184090       order wrong\n",
       "ice cream          4.048424         ice cream\n",
       "sweet tea          3.812979         sweet tea"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2-5 grams\n",
    "vegas = vectorizer1.fit_transform(r_vegas)\n",
    "terms = vectorizer1.get_feature_names()\n",
    "tf_idf = pd.DataFrame(vegas.toarray().transpose(), index=terms)\n",
    "tf_idf = tf_idf.sum(axis=1)\n",
    "score1 = pd.DataFrame(tf_idf, columns=[\"score\"])\n",
    "score1[\"term\"] = terms\n",
    "score1.sort_values(by=\"score\", ascending=False, inplace=True)\n",
    "\n",
    "score1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-grams\n",
    "vegas = vectorizer2.fit_transform(r_vegas)\n",
    "terms = vectorizer2.get_feature_names()\n",
    "tf_idf = pd.DataFrame(vegas.toarray().transpose(), index=terms)\n",
    "tf_idf = tf_idf.sum(axis=1)\n",
    "score2 = pd.DataFrame(tf_idf, columns=[\"score\"])\n",
    "score2[\"term\"] = terms\n",
    "score2.sort_values(by=\"score\", ascending=False, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-grams\n",
    "vegas = vectorizer3.fit_transform(r_vegas)\n",
    "terms = vectorizer3.get_feature_names()\n",
    "tf_idf = pd.DataFrame(vegas.toarray().transpose(), index=terms)\n",
    "tf_idf = tf_idf.sum(axis=1)\n",
    "score3 = pd.DataFrame(tf_idf, columns=[\"score\"])\n",
    "score3[\"term\"] = terms\n",
    "score3.sort_values(by=\"score\", ascending=False, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chicago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter only Chicago\n",
    "Chicago = data[data.city == 'Chicago']\n",
    "r_chicago = list(Chicago['review'].values)\n",
    "\n",
    "# lemmatize review\n",
    "r_chicago = lemma(r_chicago)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-5 grams\n",
    "chicago = vectorizer1.fit_transform(r_chicago)\n",
    "terms = vectorizer1.get_feature_names()\n",
    "tf_idf = pd.DataFrame(chicago.toarray().transpose(), index=terms)\n",
    "tf_idf = tf_idf.sum(axis=1)\n",
    "score1 = pd.DataFrame(tf_idf, columns=[\"score\"])\n",
    "score1[\"term\"] = terms\n",
    "score1.sort_values(by=\"score\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-grams\n",
    "chicago = vectorizer2.fit_transform(r_chicago)\n",
    "terms = vectorizer2.get_feature_names()\n",
    "tf_idf = pd.DataFrame(chicago.toarray().transpose(), index=terms)\n",
    "tf_idf = tf_idf.sum(axis=1)\n",
    "score2 = pd.DataFrame(tf_idf, columns=[\"score\"])\n",
    "score2[\"term\"] = terms\n",
    "score2.sort_values(by=\"score\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-grams\n",
    "chicago = vectorizer3.fit_transform(r_chicago)\n",
    "terms = vectorizer3.get_feature_names()\n",
    "tf_idf = pd.DataFrame(chicago.toarray().transpose(), index=terms)\n",
    "tf_idf = tf_idf.sum(axis=1)\n",
    "score3 = pd.DataFrame(tf_idf, columns=[\"score\"])\n",
    "score3[\"term\"] = terms\n",
    "score3.sort_values(by=\"score\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "score1.to_csv('chicago.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Los Angeles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter only LA\n",
    "LA = data[data.city == 'Los Angeles']\n",
    "r_la = list(LA['review'].values)\n",
    "\n",
    "# lemmatize review\n",
    "r_la = lemma(r_la)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-5 grams\n",
    "la = vectorizer1.fit_transform(r_la)\n",
    "terms = vectorizer1.get_feature_names()\n",
    "tf_idf = pd.DataFrame(la.toarray().transpose(), index=terms)\n",
    "tf_idf = tf_idf.sum(axis=1)\n",
    "score1 = pd.DataFrame(tf_idf, columns=[\"score\"])\n",
    "score1[\"term\"] = terms\n",
    "score1.sort_values(by=\"score\", ascending=False, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-grams\n",
    "la = vectorizer2.fit_transform(r_la)\n",
    "terms = vectorizer2.get_feature_names()\n",
    "tf_idf = pd.DataFrame(la.toarray().transpose(), index=terms)\n",
    "tf_idf = tf_idf.sum(axis=1)\n",
    "score2 = pd.DataFrame(tf_idf, columns=[\"score\"])\n",
    "score2[\"term\"] = terms\n",
    "score2.sort_values(by=\"score\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-grams\n",
    "la = vectorizer3.fit_transform(r_la)\n",
    "terms = vectorizer3.get_feature_names()\n",
    "tf_idf = pd.DataFrame(la.toarray().transpose(), index=terms)\n",
    "tf_idf = tf_idf.sum(axis=1)\n",
    "score3 = pd.DataFrame(tf_idf, columns=[\"score\"])\n",
    "score3[\"term\"] = terms\n",
    "score3.sort_values(by=\"score\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New York"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter only LA\n",
    "NY = data[data.city == 'New York']\n",
    "r_ny = list(NY['review'].values)\n",
    "\n",
    "# lemmatize review\n",
    "r_ny = lemma(r_ny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-5 grams\n",
    "ny = vectorizer1.fit_transform(r_ny)\n",
    "terms = vectorizer1.get_feature_names()\n",
    "tf_idf = pd.DataFrame(ny.toarray().transpose(), index=terms)\n",
    "tf_idf = tf_idf.sum(axis=1)\n",
    "score1 = pd.DataFrame(tf_idf, columns=[\"score\"])\n",
    "score1[\"term\"] = terms\n",
    "score1.sort_values(by=\"score\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-grams\n",
    "ny = vectorizer2.fit_transform(r_ny)\n",
    "terms = vectorizer2.get_feature_names()\n",
    "tf_idf = pd.DataFrame(ny.toarray().transpose(), index=terms)\n",
    "tf_idf = tf_idf.sum(axis=1)\n",
    "score2 = pd.DataFrame(tf_idf, columns=[\"score\"])\n",
    "score2[\"term\"] = terms\n",
    "score2.sort_values(by=\"score\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-grams\n",
    "ny = vectorizer3.fit_transform(r_ny)\n",
    "terms = vectorizer3.get_feature_names()\n",
    "tf_idf = pd.DataFrame(ny.toarray().transpose(), index=terms)\n",
    "tf_idf = tf_idf.sum(axis=1)\n",
    "score3 = pd.DataFrame(tf_idf, columns=[\"score\"])\n",
    "score3[\"term\"] = terms\n",
    "score3.sort_values(by=\"score\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "score1.to_csv('ny.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atlanta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter only LA\n",
    "Atlanta = data[data.city == 'Atlanta']\n",
    "r_atlanta = list(Atlanta['review'].values)\n",
    "\n",
    "# lemmatize review\n",
    "r_atlanta = lemma(r_atlanta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-5 grams\n",
    "atlanta = vectorizer1.fit_transform(r_atlanta)\n",
    "terms = vectorizer1.get_feature_names()\n",
    "tf_idf = pd.DataFrame(atlanta.toarray().transpose(), index=terms)\n",
    "tf_idf = tf_idf.sum(axis=1)\n",
    "score1 = pd.DataFrame(tf_idf, columns=[\"score\"])\n",
    "score1[\"term\"] = terms\n",
    "score1.sort_values(by=\"score\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-grams\n",
    "atlanta = vectorizer2.fit_transform(r_atlanta)\n",
    "terms = vectorizer2.get_feature_names()\n",
    "tf_idf = pd.DataFrame(atlanta.toarray().transpose(), index=terms)\n",
    "tf_idf = tf_idf.sum(axis=1)\n",
    "score2 = pd.DataFrame(tf_idf, columns=[\"score\"])\n",
    "score2[\"term\"] = terms\n",
    "score2.sort_values(by=\"score\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-grams\n",
    "atlanta = vectorizer3.fit_transform(r_atlanta)\n",
    "terms = vectorizer3.get_feature_names()\n",
    "tf_idf = pd.DataFrame(atlanta.toarray().transpose(), index=terms)\n",
    "tf_idf = tf_idf.sum(axis=1)\n",
    "score3 = pd.DataFrame(tf_idf, columns=[\"score\"])\n",
    "score3[\"term\"] = terms\n",
    "score3.sort_values(by=\"score\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "score1.to_csv('altan.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Houston        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter only Houston\n",
    "Houston = data[data.city == 'Houston']\n",
    "r_houston = list(Houston['review'].values)\n",
    "\n",
    "# lemmatize review\n",
    "r_houston = lemma(r_houston)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-5 grams\n",
    "houston = vectorizer1.fit_transform(r_houston)\n",
    "terms = vectorizer1.get_feature_names()\n",
    "tf_idf = pd.DataFrame(houston.toarray().transpose(), index=terms)\n",
    "tf_idf = tf_idf.sum(axis=1)\n",
    "score1 = pd.DataFrame(tf_idf, columns=[\"score\"])\n",
    "score1[\"term\"] = terms\n",
    "score1.sort_values(by=\"score\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-grams\n",
    "houston = vectorizer2.fit_transform(r_houston)\n",
    "terms = vectorizer2.get_feature_names()\n",
    "tf_idf = pd.DataFrame(houston.toarray().transpose(), index=terms)\n",
    "tf_idf = tf_idf.sum(axis=1)\n",
    "score2 = pd.DataFrame(tf_idf, columns=[\"score\"])\n",
    "score2[\"term\"] = terms\n",
    "score2.sort_values(by=\"score\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-grams\n",
    "houston = vectorizer3.fit_transform(r_houston)\n",
    "terms = vectorizer3.get_feature_names()\n",
    "tf_idf = pd.DataFrame(houston.toarray().transpose(), index=terms)\n",
    "tf_idf = tf_idf.sum(axis=1)\n",
    "score3 = pd.DataFrame(tf_idf, columns=[\"score\"])\n",
    "score3[\"term\"] = terms\n",
    "score3.sort_values(by=\"score\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portland "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter only Portland\n",
    "Portland = data[data.city == 'Portland']\n",
    "r_portland = list(Portland['review'].values)\n",
    "\n",
    "# lemmatize review\n",
    "r_portland = lemma(r_portland)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-5 grams\n",
    "portland = vectorizer1.fit_transform(r_portland)\n",
    "terms = vectorizer1.get_feature_names()\n",
    "tf_idf = pd.DataFrame(portland.toarray().transpose(), index=terms)\n",
    "tf_idf = tf_idf.sum(axis=1)\n",
    "score1 = pd.DataFrame(tf_idf, columns=[\"score\"])\n",
    "score1[\"term\"] = terms\n",
    "score1.sort_values(by=\"score\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-grams\n",
    "portland = vectorizer2.fit_transform(r_portland)\n",
    "terms = vectorizer2.get_feature_names()\n",
    "tf_idf = pd.DataFrame(portland.toarray().transpose(), index=terms)\n",
    "tf_idf = tf_idf.sum(axis=1)\n",
    "score2 = pd.DataFrame(tf_idf, columns=[\"score\"])\n",
    "score2[\"term\"] = terms\n",
    "score2.sort_values(by=\"score\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-grams\n",
    "portland = vectorizer3.fit_transform(r_portland)\n",
    "terms = vectorizer3.get_feature_names()\n",
    "tf_idf = pd.DataFrame(portland.toarray().transpose(), index=terms)\n",
    "tf_idf = tf_idf.sum(axis=1)\n",
    "score3 = pd.DataFrame(tf_idf, columns=[\"score\"])\n",
    "score3[\"term\"] = terms\n",
    "score3.sort_values(by=\"score\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dallas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter only Dallas\n",
    "Dallas = data[data.city == 'Dallas']\n",
    "r_dallas = list(Dallas['review'].values)\n",
    "\n",
    "# lemmatize review\n",
    "r_dallas = lemma(r_dallas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-5 grams\n",
    "dallas = vectorizer1.fit_transform(r_dallas)\n",
    "terms = vectorizer1.get_feature_names()\n",
    "tf_idf = pd.DataFrame(dallas.toarray().transpose(), index=terms)\n",
    "tf_idf = tf_idf.sum(axis=1)\n",
    "score1 = pd.DataFrame(tf_idf, columns=[\"score\"])\n",
    "score1[\"term\"] = terms\n",
    "score1.sort_values(by=\"score\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-grams\n",
    "dallas = vectorizer2.fit_transform(r_dallas)\n",
    "terms = vectorizer2.get_feature_names()\n",
    "tf_idf = pd.DataFrame(dallas.toarray().transpose(), index=terms)\n",
    "tf_idf = tf_idf.sum(axis=1)\n",
    "score2 = pd.DataFrame(tf_idf, columns=[\"score\"])\n",
    "score2[\"term\"] = terms\n",
    "score2.sort_values(by=\"score\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-grams\n",
    "dallas = vectorizer3.fit_transform(r_dallas)\n",
    "terms = vectorizer3.get_feature_names()\n",
    "tf_idf = pd.DataFrame(dallas.toarray().transpose(), index=terms)\n",
    "tf_idf = tf_idf.sum(axis=1)\n",
    "score3 = pd.DataFrame(tf_idf, columns=[\"score\"])\n",
    "score3[\"term\"] = terms\n",
    "score3.sort_values(by=\"score\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "score1.to_csv('dallas.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleveland "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter only Cleveland\n",
    "Cleveland = data[data.city == 'Cleveland']\n",
    "r_cleveland = list(Cleveland['review'].values)\n",
    "\n",
    "# lemmatize review\n",
    "r_cleveland = lemma(r_cleveland)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>drive thru</th>\n",
       "      <td>4.501727</td>\n",
       "      <td>drive thru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer service</th>\n",
       "      <td>2.458793</td>\n",
       "      <td>customer service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst ever</th>\n",
       "      <td>2.084463</td>\n",
       "      <td>worst ever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>somewhere else</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>somewhere else</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long wait</th>\n",
       "      <td>1.896080</td>\n",
       "      <td>long wait</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     score              term\n",
       "drive thru        4.501727        drive thru\n",
       "customer service  2.458793  customer service\n",
       "worst ever        2.084463        worst ever\n",
       "somewhere else    2.000000    somewhere else\n",
       "long wait         1.896080         long wait"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2-5 grams\n",
    "cleveland = vectorizer1.fit_transform(r_cleveland)\n",
    "terms = vectorizer1.get_feature_names()\n",
    "tf_idf = pd.DataFrame(cleveland.toarray().transpose(), index=terms)\n",
    "tf_idf = tf_idf.sum(axis=1)\n",
    "score1 = pd.DataFrame(tf_idf, columns=[\"score\"])\n",
    "score1[\"term\"] = terms\n",
    "score1.sort_values(by=\"score\", ascending=False, inplace=True)\n",
    "\n",
    "score1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-grams\n",
    "cleveland = vectorizer2.fit_transform(r_cleveland)\n",
    "terms = vectorizer2.get_feature_names()\n",
    "tf_idf = pd.DataFrame(cleveland.toarray().transpose(), index=terms)\n",
    "tf_idf = tf_idf.sum(axis=1)\n",
    "score2 = pd.DataFrame(tf_idf, columns=[\"score\"])\n",
    "score2[\"term\"] = terms\n",
    "score2.sort_values(by=\"score\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-grams\n",
    "cleveland = vectorizer3.fit_transform(r_cleveland)\n",
    "terms = vectorizer3.get_feature_names()\n",
    "tf_idf = pd.DataFrame(cleveland.toarray().transpose(), index=terms)\n",
    "tf_idf = tf_idf.sum(axis=1)\n",
    "score3 = pd.DataFrame(tf_idf, columns=[\"score\"])\n",
    "score3[\"term\"] = terms\n",
    "score3.sort_values(by=\"score\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## phrase count for high scored phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drive thru is mentioned in 12.984 % of all comments\n"
     ]
    }
   ],
   "source": [
    "# count \"drive thru\"\n",
    "import re\n",
    "\n",
    "count = 0\n",
    "for line in allreview:\n",
    "    if len(re.findall(r\"(drive thru)\", line)) >= 1:\n",
    "        count += 1\n",
    "count\n",
    "\n",
    "print(\"drive thru is mentioned in\",round((count/1525)*100,3), '% of all comments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.381418092909534"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count \"drive thru\" in Vagas\n",
    "count = 0\n",
    "for line in r_vegas:\n",
    "    if len(re.findall(r\"(drive thru)\", line)) >= 1:\n",
    "        count += 1\n",
    "\n",
    "(count/409)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrong order, order wrong, order right, or right order is mentioned in 8.656 % of all comments\n"
     ]
    }
   ],
   "source": [
    "# count \"order wrong\" , \"wrong order\" , \"order right\" , \"right order\" \"correct order\" \"order correct\"\n",
    "count = 0\n",
    "for line in allreview:\n",
    "    if len(re.findall(r\"(order wrong|wrong order|order right|right order|correct order|order correct)\", line)) >= 1:\n",
    "        count += 1\n",
    "\n",
    "print(\"wrong order, order wrong, order right, or right order is mentioned in\",round((count/1525)*100,3), '% of all comments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ice cream is mentioned in 2.689 % of all comments\n"
     ]
    }
   ],
   "source": [
    "# count \"ice cream\"\n",
    "count = 0\n",
    "for line in allreview:\n",
    "    if len(re.findall(r\"(ice cream|icecream)\", line)) >= 1:\n",
    "        count += 1\n",
    "print(\"ice cream is mentioned in\",round((count/1525)*100,3), '% of all comments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "french fry is mentioned in 2.164 % of all comments\n"
     ]
    }
   ],
   "source": [
    "# count \"french fry\"\n",
    "count = 0\n",
    "for line in allreview:\n",
    "    if len(re.findall(r\"(french fry|frenchfry|fries)\", line)) >= 1:\n",
    "        count += 1\n",
    "print(\"french fry is mentioned in\",round((count/1525)*100,3), '% of all comments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "big mac is mentioned in 0.852 % of all comments\n"
     ]
    }
   ],
   "source": [
    "# count \"big mac\"\n",
    "count = 0\n",
    "for line in allreview:\n",
    "    if len(re.findall(r\"(big mac|bigmac)\", line)) >= 1:\n",
    "        count += 1\n",
    "print(\"big mac is mentioned in\",round((count/1525)*100,3), '% of all comments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chicken nugget is mentioned in 2.098 % of all comments\n"
     ]
    }
   ],
   "source": [
    "# count \"chicken nugget\"\n",
    "count = 0\n",
    "for line in allreview:\n",
    "    if len(re.findall(r\"(chicken nugget)\", line)) >= 1:\n",
    "        count += 1\n",
    "print(\"chicken nugget is mentioned in\",round((count/1525)*100,3), '% of all comments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ced coffee is mentioned in 1.77 % of all comments\n"
     ]
    }
   ],
   "source": [
    "#count iced coffee\n",
    "count = 0\n",
    "for line in allreview:\n",
    "    if len(re.findall(r\"(iced coffee)\", line)) >= 1:\n",
    "        count += 1\n",
    "print(\"ced coffee is mentioned in\",round((count/1525)*100,3), '% of all comments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sweet tea is mentioned in 1.705 % of all comments\n"
     ]
    }
   ],
   "source": [
    "#count sweet tea\n",
    "count = 0\n",
    "for line in allreview:\n",
    "    if len(re.findall(r\"(sweet tea)\", line)) >= 1:\n",
    "        count += 1\n",
    "print(\"sweet tea is mentioned in\",round((count/1525)*100,3), '% of all comments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "late night is mentioned in 1.508 % of all comments\n"
     ]
    }
   ],
   "source": [
    "# count \"late night\"\n",
    "count = 0\n",
    "for line in allreview:\n",
    "    if len(re.findall(r\"(late night|latenight)\", line)) >= 1:\n",
    "        count += 1\n",
    "print(\"late night is mentioned in\",round((count/1525)*100,3), '% of all comments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parking or parking lot is mentioned in 3.148 % of all comments\n"
     ]
    }
   ],
   "source": [
    "# count \"parking lot\"\n",
    "count = 0\n",
    "for line in allreview:\n",
    "    if len(re.findall(r\"(parking lot|parking)\", line)) >= 1:\n",
    "        count += 1\n",
    "print(\"parking or parking lot is mentioned in\",round((count/1525)*100,3), '% of all comments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
